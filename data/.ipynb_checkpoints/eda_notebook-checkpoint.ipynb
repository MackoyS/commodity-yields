{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: netCDF4 in c:\\users\\coldk\\anaconda3\\envs\\learn-env\\lib\\site-packages (1.5.4)\n",
      "Requirement already satisfied: cftime in c:\\users\\coldk\\anaconda3\\envs\\learn-env\\lib\\site-packages (from netCDF4) (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.9 in c:\\users\\coldk\\anaconda3\\envs\\learn-env\\lib\\site-packages (from netCDF4) (1.18.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install netCDF4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting bash style code and making sure xarray is installed\n",
    "# %%bash\n",
    "# pip install xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for initial data cleaning and EDA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import xarray as xr\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from random import gauss, seed\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging NetCDF Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After taking a look at the data from https://doi.pangaea.de/10.1594/PANGAEA.909132 I found out that the dataset is in the nc4 file type. I'll need to merge all of the years together as well as convert them into a csv in order to get that information into a dataframe so that I can start my EDA. The first part is my exploration in making this merger through a practice file and then I'll apply my technique to the main file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yield_1981.nc4\n",
      "yield_1982.nc4\n",
      "yield_1983.nc4\n",
      "yield_1984.nc4\n"
     ]
    }
   ],
   "source": [
    "# Looking at test practice merge folder\n",
    "!ls data\\practice\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_storage_directory = 'C:/Users/Coldk/Documents/Flatiron/capstone/data/'\n",
    "csv_dir = local_storage_directory + 'csv/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter format not correct - \"practice\".\n"
     ]
    }
   ],
   "source": [
    "ls $data/practice/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 292K\n",
      "-rw-r--r-- 1 Coldk 197609 39K Jan 27  2020 yield_1981.nc4\n",
      "-rw-r--r-- 1 Coldk 197609 84K Jan 27  2020 yield_1982.nc4\n",
      "-rw-r--r-- 1 Coldk 197609 84K Jan 27  2020 yield_1983.nc4\n",
      "-rw-r--r-- 1 Coldk 197609 84K Jan 27  2020 yield_1984.nc4\n"
     ]
    }
   ],
   "source": [
    "# Creating a directory where the list of files is stored\n",
    "files_to_convert = local_storage_directory + 'practice/'\n",
    "!ls -lh $files_to_convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yield_1981.nc4 has been processed to .csv\n",
      "yield_1982.nc4 has been processed to .csv\n",
      "yield_1983.nc4 has been processed to .csv\n",
      "yield_1984.nc4 has been processed to .csv\n"
     ]
    }
   ],
   "source": [
    "# Set a loop to create a .csv file for each .nc file listed in `files_to_convert`\n",
    "for filename in os.listdir(files_to_convert):\n",
    "    ds = xr.open_dataset(files_to_convert + filename)\n",
    "    df = ds.to_dataframe()\n",
    "    df.to_csv(csv_dir + filename[:-3] + '.csv')\n",
    "    print (filename + ' has been processed to .csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 16M\n",
      "-rw-r--r-- 1 Coldk 197609 3.8M Nov  1 13:22 yield_1981..csv\n",
      "-rw-r--r-- 1 Coldk 197609 3.9M Nov  1 13:22 yield_1982..csv\n",
      "-rw-r--r-- 1 Coldk 197609 3.9M Nov  1 13:22 yield_1983..csv\n",
      "-rw-r--r-- 1 Coldk 197609 3.9M Nov  1 13:22 yield_1984..csv\n"
     ]
    }
   ],
   "source": [
    "!ls -lrth $csv_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               var\n",
      "lat    lon        \n",
      "-89.75 0.25    NaN\n",
      "       0.75    NaN\n",
      "       1.25    NaN\n",
      "       1.75    NaN\n",
      "       2.25    NaN\n",
      "...            ...\n",
      " 89.75 357.75  NaN\n",
      "       358.25  NaN\n",
      "       358.75  NaN\n",
      "       359.25  NaN\n",
      "       359.75  NaN\n",
      "\n",
      "[259200 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.636000    48\n",
       "15.635999    30\n",
       "15.636001    23\n",
       "15.636002    13\n",
       "0.364241     12\n",
       "             ..\n",
       "2.630771      1\n",
       "10.522892     1\n",
       "3.630702      1\n",
       "1.315280      1\n",
       "4.000012      1\n",
       "Name: var, Length: 12455, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['var'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246573"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Oh gosh I can't use this.\n",
    "df['var'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
